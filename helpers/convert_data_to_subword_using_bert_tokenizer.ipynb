{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leshanbog\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\leshanbog\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\leshanbog\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\leshanbog\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\leshanbog\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\leshanbog\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained(\n",
    "    r'C:\\Users\\leshanbog\\Documents\\model\\bert\\rubert_cased_L-12_H-768_A-12_v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ria_enum(input_file):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as r:\n",
    "        for line in r:\n",
    "            data = json.loads(line.strip())\n",
    "            title = data[\"title\"]\n",
    "            text = data[\"text\"]\n",
    "            clean_text = BeautifulSoup(text, 'html.parser').text.replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "            if len(clean_text) < 10 or not title:\n",
    "                continue\n",
    "            yield clean_text, title\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ria_train = r'C:\\Users\\leshanbog\\Documents\\dataset\\ria\\ria.shuffled.test.json'\n",
    "ria_train_subword = r'C:\\Users\\leshanbog\\Documents\\dataset\\ria\\ria_test_subword.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 documents\n",
      "Processed 1000 documents\n",
      "Processed 2000 documents\n",
      "Processed 3000 documents\n",
      "Processed 4000 documents\n",
      "Processed 5000 documents\n",
      "Processed 6000 documents\n",
      "Processed 7000 documents\n",
      "Processed 8000 documents\n",
      "Processed 9000 documents\n",
      "Processed 10000 documents\n",
      "Processed 11000 documents\n",
      "Processed 12000 documents\n",
      "Processed 13000 documents\n",
      "Processed 14000 documents\n",
      "Processed 15000 documents\n",
      "Processed 16000 documents\n",
      "Processed 17000 documents\n",
      "Processed 18000 documents\n",
      "Processed 19000 documents\n",
      "Processed 20000 documents\n",
      "Processed 21000 documents\n",
      "Processed 22000 documents\n",
      "Processed 23000 documents\n",
      "Processed 24000 documents\n",
      "Processed 25000 documents\n",
      "Processed 26000 documents\n",
      "Processed 27000 documents\n",
      "Processed 28000 documents\n",
      "Processed 29000 documents\n",
      "Processed 30000 documents\n",
      "Processed 31000 documents\n",
      "Processed 32000 documents\n",
      "Processed 33000 documents\n",
      "Processed 34000 documents\n",
      "Processed 35000 documents\n",
      "Processed 36000 documents\n",
      "Processed 37000 documents\n",
      "Processed 38000 documents\n",
      "Processed 39000 documents\n",
      "Processed 40000 documents\n",
      "Processed 41000 documents\n",
      "Processed 42000 documents\n",
      "Processed 43000 documents\n",
      "Processed 44000 documents\n",
      "Processed 45000 documents\n",
      "Processed 46000 documents\n",
      "Processed 47000 documents\n",
      "Processed 48000 documents\n",
      "Processed 49000 documents\n"
     ]
    }
   ],
   "source": [
    "with open(ria_train_subword, 'w', encoding='utf-8') as f:\n",
    "    for j, (text, title) in enumerate(ria_enum(ria_train)):\n",
    "        if j % 1000 == 0:\n",
    "            print('Processed {} documents'.format(j))\n",
    "            \n",
    "        f.write(' '.join(tokenizer.tokenize(text)) + '\\t')\n",
    "        f.write(' '.join(tokenizer.tokenize(title)) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
